# -*- coding: utf-8 -*-
"""Cardiovascular Disease.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H3CE_F5iUALHgYflM3_1a0O79jKDuiRQ
"""

""" Link To Kaggle Dataset: 
https://www.kaggle.com/sulianova/cardiovascular-disease-dataset
"""
import time

t0 = time.time()

! pip install -q kaggle
from google.colab import files 
files.upload()
! mkdir ~/.kaggle 
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d sulianova/cardiovascular-disease-dataset

!unzip cardiovascular-disease-dataset.zip

"""Data description

Features:

    Age | age | int (days)
    Height | height | int (cm) |
    Weight | weight | float (kg) |
    Gender | gender | categorical code | 1: women, 2: man
    Systolic blood pressure | ap_hi | int |
    Diastolic blood pressure | ap_lo | int |
    Cholesterol | cholesterol | 1: normal, 2: above normal, 3: well above normal |
    Glucose | gluc | 1: normal, 2: above normal, 3: well above normal |
    Smoking | smoke | binary |
    Alcohol intake | alco | binary |
    Physical activity | active | binary |
    **Presence or absence of cardiovascular disease** | **Target Variable** | cardio | binary |

All of the dataset values were collected at the moment of medical examination. 
"""

import pandas as pd

df = pd.read_csv('/content/cardio_train.csv',sep=";")
df

"""Add BMI Column, need to convert cm to m for the height column. 

BMI = weight / height * height
"""

df['height'] = df['height'] / 100

"""Calculate the body mass index based on height and weight"""

df['BMI'] = (df['weight'])/((df['height']) * df['height'])
df

"""Define obesity levels based on thresholds from the CDC. Link Below:

https://www.cdc.gov/obesity/adult/defining.html
"""

outliers = ((df["ap_hi"]>250) | (df["ap_lo"]>200) )
print("There are {} outliers".format(df[outliers]["cardio"].count()))
df = df[~outliers]
df

BMI = list(df['BMI'])
print(BMI)
obesity = []
numeric = []
for x in range(len(BMI)):
  if (BMI[x] <= 18.5):
    obesity.append('Under Weight')
    numeric.append(0)
  elif (18.5 < BMI[x] <= 25):
    obesity.append('Normal')
    numeric.append(1)
  elif (25 < BMI[x] <= 30):
    obesity.append('Overweight')
    numeric.append(2)
  elif (30 < BMI[x] <= 35):
    obesity.append('Class 1 Obesity')
    numeric.append(3)
  elif (35 < BMI[x] <= 40):
    obesity.append('Class 2 Obesity')
    numeric.append(4)
  else: 
    obesity.append('Class 3 Obesity')
    numeric.append(5)

df['obesity_level'] = obesity

df

df.info()

df.drop("id",axis=1,inplace=True)

df

"""Convert all columns to float64"""

df['age'] = df['age'].astype(float)
df['gender'] = df['gender'].astype(float)
df['height'] = df['height'].astype(float)
df['weight'] = df['weight'].astype(float)
df['ap_hi'] = df['ap_hi'].astype(float)
df['ap_lo'] = df['ap_lo'].astype(float)
df['cholesterol'] = df['cholesterol'].astype(float)
df['gluc'] = df['gluc'].astype(float)
df['smoke'] = df['smoke'].astype(float)
df['alco'] = df['alco'].astype(float)
df['active'] = df['active'].astype(float)
df['BMI'] = df['BMI'].astype(float)
df['cardio'] = df['cardio'].astype(float)

"""Statistics By Column"""

df.describe()

df.isnull()

"""Check for any missing values"""

df.isna().any().any()

"""False output means that there are no missing values

Visualization 1: Group the data according to gender and count the rows. Then use a bar chart to see basic statistics by gender
"""

dfGender = df.groupby('gender').std()

dfGender

"""The bar graph below shows the counts of cardiovascular infections by gender and whether or not they have the disease"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
# %matplotlib inline
sns.countplot(x='obesity_level', data=df, hue='cardio')
plt.xticks(rotation=45)
plt.show()

"""The graph below shows the counts of cardiovascular disease based on glucose sugar levels where the blue bar means they don't have the disease and the brown bar means they have it."""

sns.countplot(x='gender', hue='cardio', data=df)
plt.show()

"""Check for outliers



A study published by doctors showed the maximum blood pressure of 270/260

As a result, drop the ap_hi outlier values and ap_lo outlier values accordingly.

Represent obesity level in a numerical format
"""

df['obesity_level'] = numeric
df

df = df[['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'BMI', 'obesity_level', 'cardio']]

df

"""For ML purposes remove the target variable (cardio) from the dataset"""

X = df.values[:, 0:13]
Y = df.values[:,-1]

"""Import decision tree library and fit data to the model"""

import sklearn 
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100)

X_train

dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)

"""Make a prediction on the decision tree from the X_test variable"""

y_pred = dt.predict(X_test)

"""Print out confusion matrix for the decision tree"""

import numpy as np
from sklearn.metrics import confusion_matrix
result = np.array(y_test)
predictions = np.array(y_pred)
confusion_matrix(result, predictions)

"""Make a prediction on unseen/made up data"""

data = [[10000, 2, 1.80, 85, 110, 60, 2, 1, 0, 1, 0, 20, 1]]
new_data = dt.predict(data)
new_data

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

"""Graph the actual tree"""

!pip install -q graphviz
import graphviz
from matplotlib import pyplot as plt
from sklearn import datasets
from sklearn.tree import DecisionTreeClassifier 
from sklearn import tree

fn=["age","gender","height","weight","ap_hi","ap_lo","cholesterol","gluc","smoke","alco","active","BMI","obesity_level"]
cn=['Positive', 'Negative']

fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (30,30), dpi=300)
tree.plot_tree(dt,
               feature_names = fn, 
               class_names=cn,
               filled = True);

"""Import Naive Bayes Classifier and fit the data"""

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(X, Y);

"""Make a prediction"""

y_pred = model.predict(X_test)
y_pred

"""View the confusion matrix for the model"""

result = np.array(y_test)
predictions = np.array(y_pred)
confusion_matrix(result, predictions)

print(classification_report(y_test, y_pred))

"""Predict on the same unseen data as before"""

data = [[10000, 2, 1.80, 85, 110, 60, 2, 1, 0, 1, 0, 20, 1]]
new_data = model.predict(data)
new_data

"""Analysis Continued"""

import pandas as pd
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (20,10)
from sklearn import model_selection
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
import warnings
warnings.filterwarnings("ignore")

def min_max_normalization(df):
    # copy the dataframe
    df_norm = df.copy()
    # apply min-max scaling
    for column in df_norm.columns:
        df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())
        
    return df_norm

data = min_max_normalization(df)
df = data
df

#Set predicitve variables
 
X = df.values[:, 0:13]
Y = df.values[:,-1]

random_seed = 12

import pandas as pd
from sklearn import preprocessing

min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(X)
X = pd.DataFrame(x_scaled)

outcome = []
model_names = []
models = [('LogReg', LogisticRegression()), 
          ('DecTree', DecisionTreeClassifier()),
          ('KNN', KNeighborsClassifier()),
          ('LinDisc', LinearDiscriminantAnalysis()),
          ('GaussianNB', GaussianNB())]

for model_name, model in models:
    k_fold_validation = model_selection.KFold(n_splits=10, random_state=random_seed)
    results = model_selection.cross_val_score(model, X, Y, cv=k_fold_validation, scoring='accuracy')
    outcome.append(results)
    model_names.append(model_name)
    output_message = "%s| Accuracy=%f" % (model_name, results.mean())
    print(output_message)

fig = plt.figure()
fig.suptitle('Machine Learning Model Comparison')
ax = fig.add_subplot(111)
plt.boxplot(outcome)
plt.xlabel('Models')
plt.ylabel('Accuracies')
ax.set_xticklabels(model_names)
plt.show()

import numpy as np

uniqueValues, occurCount = np.unique(Y, return_counts=True)
 
print("Unique Values : " , uniqueValues)
print("Occurrence Count : ", occurCount)

import numpy as nump
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
enc = OneHotEncoder()
Y = enc.fit_transform(Y[:, nump.newaxis]).toarray()

X = df.values[:, 0:13]
Y = df.values[:,-1]
from sklearn.model_selection import train_test_split
X_train,X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=42)

Y

df

from sklearn import preprocessing

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

tensorflow.keras.backend.set_floatx('float64')

# fix random seed for reproducibility
np.random.seed(7)

model = Sequential()
model.add(Dense(7, input_dim=13, activation='relu'))
model.add(Dense(7, activation='relu'))
model.add(Dense(5, activation='relu'))
model.add(Dense(1, activation='sigmoid'))


model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])

ann = model.fit(X_train, y_train, epochs=400, batch_size=1024, validation_data = (X_test,y_test), shuffle=True)

(loss_score, accuracy_score) = model.evaluate(X_test,y_test,verbose=0)
print('Loss score',loss_score)
print('Accuracy score',accuracy_score)

plt.plot(ann.history['accuracy'])
plt.plot(ann.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'test'])
plt.show()

plt.plot(ann.history['loss'])
plt.plot(ann.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'test'])
plt.show()

model.summary()

pred=model.predict(X_test)
pred_digits=np.argmax(pred,axis=1)

from sklearn.metrics import classification_report
print(classification_report(y_test, pred.round()))

from sklearn.metrics import confusion_matrix
rounded_labels=np.argmax(pred_digits, axis=0)
confusion_matrix = confusion_matrix(y_test, pred.round())
print(confusion_matrix)

df

data = [[10000, 2, 1.80, 85, 110, 60, 2, 1, 0, 1, 0, 20, 1]]
new_data = model.predict(data)
new_data

"""Implement K - Means Clustering"""

from sklearn.cluster import KMeans

kmeans_clusterer = KMeans()
kmeans_clusterer

"""Find optimal number of clusters"""

from sklearn.cluster import KMeans
helper=[]
coordinates = df[['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'BMI', 'obesity_level']].values
for i in range(1,14): 
     kmeans = KMeans(n_clusters=i)
     kmeans.fit(coordinates)
     helper.append(kmeans.inertia_)
plt.figure.figsize = (4,4)
plt.plot(range(1, 14),helper)
plt.title('The Elbow Method Graph')
plt.xlabel('Number of clusters')
plt.ylabel('Value')
plt.show()

from sklearn.cluster import KMeans

from sklearn.metrics import silhouette_score, silhouette_samples
range_n_clusters = range(2,8)
coordinates = df[['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'BMI', 'obesity_level']].values

for k in range_n_clusters:
    cluster_model = KMeans(n_clusters=k)
    cluster_labels = cluster_model.fit_predict(coordinates)
    silhouette_avg = silhouette_score(coordinates, cluster_labels)
    print("For k =", k, "The average silhouette_score is :", silhouette_avg)

"""Use 6 clusters because it provided the highest silhouette score"""

kmeans_clusterer = KMeans(n_clusters=6)
kmeans_clusterer

label = kmeans_clusterer.fit_predict(df)
label

kmeans_clusterer.fit(X_train, y_train)
y_pred = kmeans_clusterer.predict(X_test)
y_pred

from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_test, y_pred)
print(confusion_matrix)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

centroids = kmeans_clusterer.cluster_centers_
labels = kmeans_clusterer.labels_
X_kmeans = df.iloc[:, [0,1,2,3,4,5,6,7,8,9,10,11,12, 13]].values
X_kmeans2 = df

import matplotlib.cm as cm
for x in range(0,13):
  for y in range (0,13):
    plt.scatter(X_kmeans[:,x],X_kmeans[:,y],c=label,cmap='rainbow')
    xlabel, ylabel = '',''
    if (x == 0):
      xlabel = 'age'
    elif (x == 1):
      xlabel = 'gender'
    elif (x == 2):
      xlabel = 'height'
    elif (x==3):
      xlabel = 'weight'
    elif (x==4):
      xlabel = 'ap_hi'
    elif (x==5):
      xlabel = 'ap_lo'
    elif (x==6):
      xlabel = 'cholesterol'
    elif (x==7):
      xlabel = 'glucose'
    elif (x==8):
      xlabel = 'smoke'
    elif (x==9):
      xlabel = 'alcohol'
    elif (x==10):
      xlabel = 'active'
    elif (x==11):
      xlabel = 'body mass index'
    elif (x==12):
      xlabel = 'obesity_level'
    elif (x==13):
      xlabel = 'cardiovascular disease'
    if (y == 0):
      ylabel = 'age'
    elif (y == 1):
      ylabel = 'gender'
    elif (y == 2):
      ylabel = 'height'
    elif (y==3):
      ylabel = 'weight'
    elif (y==4):
      ylabel = 'ap_hi'
    elif (y==5):
      ylabel = 'ap_lo'
    elif (y==6):
      ylabel = 'cholesterol'
    elif (y==7):
      ylabel = 'glucose'
    elif (y==8):
      ylabel = 'smoke'
    elif (y==9):
      ylabel = 'alcohol'
    elif (y==10):
      ylabel = 'active'
    elif (y==11):
      ylabel = 'body mass index'
    elif (y==12):
      ylabel = 'obesity_level'
    elif (y==13):
      ylabel = 'cardiovascular disease'
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.suptitle(xlabel+" vs "+ylabel)
    plt.colorbar()
    plt.show()

df

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn import metrics

logreg = LogisticRegression()
logreg.fit(X_train, y_train)

y_pred = logreg.predict(X_test)
pred_digits=np.argmax(y_pred,axis=0)
print('Accuracy of logistic regression: {:.4f}'.format(logreg.score(X_test, y_test)))

"""Print Confusion Matrix"""

from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_test, y_pred)
print(confusion_matrix)

"""Precision, Recall, F1-Measure """

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
res = roc_auc_score(y_test, logreg.predict(X_test))
false, true, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])
plt.figure()
plt.plot(false, true, label='Logistic Regression (area under curve = %0.4f)' % res)
plt.plot([0, 1], [0, 1],'r--')
plt.xlabel('False Positive')
plt.ylabel('True Positive')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()

"""**Linear Regression** 

Compare all columns in the dataframe against the target variable cardiovascular disease
"""

import matplotlib.pyplot as plt  
import pandas as pd  
from sklearn.linear_model import LinearRegression
from sklearn import linear_model

column = ['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'BMI', 'obesity_level']

for a in range(0,13):
    x = df.iloc[:, a].values.reshape(-1, 1)
    y = df.iloc[:, 1].values.reshape(-1, 1)

    xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = .25, random_state = 0)
    linear_regressor = LinearRegression()  
    linear_regressor.fit(xTrain, yTrain)  
    Y_pred = linear_regressor.predict(xTest)  
    plt.scatter(x, y)
    plt.title("Linear Regression of: "+column[a])
    plt.xlabel("Cardiovascular Disease")
    plt.ylabel("Prediction")
    plt.plot(xTest, Y_pred, color='red')
    plt.show()

linear_regressor = LinearRegression()  
linear_regressor.fit(X_train, y_train)  
y_pred = linear_regressor.predict(X_test)
y_pred

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred.round(), normalize=True)

from sklearn.metrics import precision_recall_fscore_support
print(precision_recall_fscore_support(y_test, y_pred.round(), average='macro'))
print(precision_recall_fscore_support(y_test, y_pred.round(), average='micro'))
print(precision_recall_fscore_support(y_test, y_pred.round(), average='weighted'))

import math
t1 = time.time()

total = t1-t0

print('Total time needed to run entire notebook',round(total/60,2),'minutes')